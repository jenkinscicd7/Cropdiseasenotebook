{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bcc74b1-7b77-4705-a531-37ec3d5121f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import PIL.Image as Image\n",
    "import os,glob\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pylab as plt\n",
    "import tensorflow as tf \n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "370cc2f9-a60e-49eb-88e6-816806f2cb73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (224, 224)\n",
    "\n",
    "import os\n",
    "os.environ[\"TFHUB_CACHE_DIR\"] = \"./tfhub_cache\"\n",
    "\n",
    "\n",
    "classifier = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\", input_shape=IMAGE_SHAPE+(3,))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b49714cc-22b5-4050-8af7-bd9783bec2ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_SHAPE+(3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8bf2e07-55e4-4f1f-8990-2554985a40f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b944fe6b33c6449d8e722727a3443529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classes: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading class: Potato___Early_blight\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0563e0d6437a44d8bef25cdf757469a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Images in Potato___Early_blight:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading class: Potato___healthy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f81dac4bbe99483fa3333681f2990032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Images in Potato___healthy:   0%|          | 0/152 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading class: Potato___Late_blight\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a566263fcf4f4fad2b3dd1fe5a0466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Images in Potato___Late_blight:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_dir = Path('plant-village')\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Iterate through each subdirectory (representing a class)\n",
    "for class_dir in tqdm(base_dir.iterdir(), desc=\"Classes\"):\n",
    "    if class_dir.is_dir():\n",
    "        label = class_dir.name  # e.g. \"Potato___Early_blight\"\n",
    "        print(f\"Loading class: {label}\")\n",
    "\n",
    "        # Iterate through images in this class folder\n",
    "        for img_path in tqdm(list(class_dir.glob(\"*.jpg\")), desc=f\"Images in {label}\", leave=False):\n",
    "            img = cv2.imread(str(img_path))\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (224, 224))\n",
    "                X.append(img)\n",
    "                y.append(label)  # Use label instead of slicing filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f3a3244-0f28-4f29-ac04-7e7b0a322d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Early blight', 'Healthy', 'Late blight']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASS_NAMES = [\"Early blight\", \"Healthy\", \"Late blight\"]\n",
    "CLASS_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7535f59-6da1-401f-9bad-5bf90e2278ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of an image in X_train:  (224, 224, 3)\n",
      "Shape of an image in X_test:  (224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "print (\"Shape of an image in X_train: \", X_train[0].shape)\n",
    "print (\"Shape of an image in X_test: \", X_test[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfe67d8f-179c-42ab-8bae-16f063db48ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(y)  # <- all at once\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)  # Shape: (N,)\n",
    "y_test = np.array(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d91734ae-67da-4bcf-8549-d80c048288f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Shape:  (1441, 224, 224, 3)\n",
      "X_test Shape:  (711, 224, 224, 3)\n",
      "y_train Shape:  (1441,)\n",
      "y_test Shape:  (711,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train Shape: \", X_train.shape)\n",
    "print(\"X_test Shape: \", X_test.shape)\n",
    "print(\"y_train Shape: \", y_train.shape)\n",
    "print(\"y_test Shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c3fbd20-8749-45c6-9003-6d2fc0b47fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_train / 255.0\n",
    "X_test_scaled = X_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffe05209-ae41-45c3-8e02-c140e6a6e818",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_extractor_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "pretrained_model_without_top_layer = hub.KerasLayer(\n",
    "    feature_extractor_model, input_shape=(224, 224, 3), trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "677ea8a3-73a7-4677-b5b3-77fc389f6db3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cdba70e-8794-453e-9bed-90bcef079d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer_1 (KerasLayer)  (None, 1280)              2257984   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 3843      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2261827 (8.63 MB)\n",
      "Trainable params: 3843 (15.01 KB)\n",
      "Non-trainable params: 2257984 (8.61 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_of_classes = 3\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    pretrained_model_without_top_layer,\n",
    "    tf.keras.layers.Dense(num_of_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26fa48df-2040-4ec4-8c7d-e673dc82e8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "46/46 [==============================] - 86s 1s/step - loss: 0.5429 - acc: 0.8022\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 51s 1s/step - loss: 0.2140 - acc: 0.9410\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 49s 1s/step - loss: 0.1581 - acc: 0.9570\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 50s 1s/step - loss: 0.1263 - acc: 0.9639\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 49s 1s/step - loss: 0.1110 - acc: 0.9688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x19cc4a319c0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=[\"acc\"])\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6219d30-7727-4888-96b4-8ad59f3f96b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_models/crops\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_models/crops\\assets\n"
     ]
    }
   ],
   "source": [
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83b94c23-951d-4c3f-8aee-f621c8143829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_models/cr\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_models/cr\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('../saved_models/cr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cf4aa6b-c499-48d5-8ed3-6d90f82135e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_models/crop\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_models/crop\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('../saved_models/crop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9b0e83f-2ee7-4390-b5ba-0d35b5cd650b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: bforetf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: bforetf\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('bforetf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73a3dd87-78a5-41ea-b7fe-40a867cdc4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"bforetf\")\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63f7b74-59db-4cd1-9832-d644dbc1999f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
